// swift-interface-format-version: 1.0
// swift-compiler-version: Apple Swift version 6.1.2 effective-5.10 (swiftlang-6.1.2.1.2 clang-1700.0.13.5)
// swift-module-flags: -target arm64-apple-ios11.0 -enable-objc-interop -enable-library-evolution -swift-version 5 -enforce-exclusivity=checked -O -enable-experimental-feature DebugDescriptionMacro -enable-bare-slash-regex -module-name LivenessCloud
// swift-module-flags-ignorable: -no-verify-emitted-module-interface -interface-compiler-version 6.1.2
import ARKit
import AVFoundation
import Accelerate
import Combine
import CoreGraphics
import CoreImage
import CoreML
import CoreMedia
import CoreVideo
import CryptoSwift
import Foundation
import KeychainSwift
@_exported import LivenessCloud
import Metal
import MetalKit
import MobileCoreServices
import ObjectMapper
import SignManager
import Swift
import UIKit
import VideoToolbox
import Vision
import _Concurrency
import _StringProcessing
import _SwiftConcurrencyShims
public func argmax(_ array: [Swift.Float], count: Swift.Int? = nil) -> (Swift.Int, Swift.Float)
public func argmax(_ ptr: Swift.UnsafePointer<Swift.Float>, count: Swift.Int, stride: Swift.Int = 1) -> (Swift.Int, Swift.Float)
public func argmax(_ array: [Swift.Double], count: Swift.Int? = nil) -> (Swift.Int, Swift.Double)
public func argmax(_ ptr: Swift.UnsafePointer<Swift.Double>, count: Swift.Int, stride: Swift.Int = 1) -> (Swift.Int, Swift.Double)
public func clamp<T>(_ x: T, min: T, max: T) -> T where T : Swift.Comparable
public func sigmoid(_ x: Swift.Float) -> Swift.Float
public func sigmoid(_ x: Swift.Double) -> Swift.Double
public func sigmoid(_ x: Swift.UnsafeMutablePointer<Swift.Float>, count: Swift.Int)
public func sigmoid(_ x: Swift.UnsafeMutablePointer<Swift.Double>, count: Swift.Int)
public func softmax(_ x: [Swift.Float]) -> [Swift.Float]
extension UIKit.UIImage {
  @nonobjc public func toByteArrayRGBA() -> [Swift.UInt8]?
  @nonobjc public class func fromByteArrayRGBA(_ bytes: [Swift.UInt8], width: Swift.Int, height: Swift.Int, scale: CoreFoundation.CGFloat = 0, orientation: UIKit.UIImage.Orientation = .up) -> UIKit.UIImage?
  @nonobjc public class func fromByteArrayGray(_ bytes: [Swift.UInt8], width: Swift.Int, height: Swift.Int, scale: CoreFoundation.CGFloat = 0, orientation: UIKit.UIImage.Orientation = .up) -> UIKit.UIImage?
}
public func rotate90PixelBuffer(from srcPixelBuffer: CoreVideo.CVPixelBuffer, to dstPixelBuffer: CoreVideo.CVPixelBuffer, factor: Swift.UInt8)
public func rotate90PixelBuffer(_ srcPixelBuffer: CoreVideo.CVPixelBuffer, factor: Swift.UInt8) -> CoreVideo.CVPixelBuffer?
extension CoreGraphics.CGImage {
  public func pixelBuffer() -> CoreVideo.CVPixelBuffer?
  public func pixelBuffer(width: Swift.Int, height: Swift.Int, orientation: ImageIO.CGImagePropertyOrientation) -> CoreVideo.CVPixelBuffer?
  public func pixelBufferGray() -> CoreVideo.CVPixelBuffer?
  public func pixelBufferGray(width: Swift.Int, height: Swift.Int, orientation: ImageIO.CGImagePropertyOrientation) -> CoreVideo.CVPixelBuffer?
  public func pixelBuffer(width: Swift.Int, height: Swift.Int, pixelFormatType: Darwin.OSType, colorSpace: CoreGraphics.CGColorSpace, alphaInfo: CoreGraphics.CGImageAlphaInfo, orientation: ImageIO.CGImagePropertyOrientation) -> CoreVideo.CVPixelBuffer?
}
extension CoreGraphics.CGImage {
  public static func create(pixelBuffer: CoreVideo.CVPixelBuffer) -> CoreGraphics.CGImage?
  public static func create(pixelBuffer: CoreVideo.CVPixelBuffer, context: CoreImage.CIContext) -> CoreGraphics.CGImage?
}
extension CoreML.MLModel {
  public func imageConstraint(forInput inputName: Swift.String) -> CoreML.MLImageConstraint?
}
@available(iOS 13.0, tvOS 13.0, *)
extension CoreML.MLModel {
  public func featureValue(fromUIImage image: UIKit.UIImage, forInput inputName: Swift.String, orientation: ImageIO.CGImagePropertyOrientation = .up, options: [CoreML.MLFeatureValue.ImageOption : Any]? = nil) -> CoreML.MLFeatureValue?
}
@available(iOS 13.0, tvOS 13.0, macOS 10.15, *)
extension CoreML.MLModel {
  public func featureValue(fromCGImage image: CoreGraphics.CGImage, forInput inputName: Swift.String, orientation: ImageIO.CGImagePropertyOrientation = .up, options: [CoreML.MLFeatureValue.ImageOption : Any]? = nil) -> CoreML.MLFeatureValue?
  public func featureValue(fromImageAt url: Foundation.URL, forInput inputName: Swift.String, orientation: ImageIO.CGImagePropertyOrientation = .up, options: [CoreML.MLFeatureValue.ImageOption : Any]? = nil) -> CoreML.MLFeatureValue?
}
@_inheritsConvenienceInitializers @available(iOS 13.0, *)
@objc public class Networking : ObjectiveC.NSObject {
  @objc public static let shared: LivenessCloud.Networking
  @objc public func setup(appId: Swift.String, logLevel: LivenessCloud.LogLevel = .debug, url: Swift.String, publicKey: Swift.String, privateKey: Swift.String, deviceId: Swift.String = "")
  @objc public func generateDeviceInfor(deviceId: Swift.String = "", additionParam: [Swift.String : Any] = [:], paramHeader: [Swift.String : Swift.String] = [:], ownerId: Swift.String = "") -> LivenessCloud.LivenessResponse
  @objc public func resetDeviceInfo()
  @objc override dynamic public init()
  @objc deinit
}
@available(iOS 13.0, *)
extension LivenessCloud.Networking {
  public func doThermalFaceAntiSpoofingCheck(normalImage: UIKit.UIImage, thermalImage: UIKit.UIImage) async throws -> [Swift.String : Any]
  public func doFaceAntiSpoofingCheck(image: UIKit.UIImage) async throws -> [Swift.String : Any]
  public func doFlashFaceAntiSpoofingCheck(image: UIKit.UIImage, color: Swift.Int) async throws -> [Swift.String : Any]
  @objc dynamic public func initTransaction(duration: Swift.Int = 30, additionParam: [Swift.String : Any] = [:], paramHeader: [Swift.String : Swift.String] = [:], clientTransactionId: Swift.String = "") async throws -> LivenessCloud.LivenessResponse
  @objc dynamic public func registerFace(faceImage: UIKit.UIImage, additionParam: [Swift.String : Any] = [:], paramHeader: [Swift.String : Swift.String] = [:]) async throws -> LivenessCloud.LivenessResponse
}
public struct MultipartRequest {
  public let boundary: Swift.String
  public init(boundary: Swift.String = UUID().uuidString)
  public mutating func add(key: Swift.String, value: Swift.String)
  public mutating func add(key: Swift.String, fileName: Swift.String, fileMimeType: Swift.String, fileData: Foundation.Data)
  public var httpContentTypeHeadeValue: Swift.String {
    get
  }
  public var httpBody: Foundation.Data {
    get
  }
}
public struct BoundingBox {
  public let classIndex: Swift.Int
  public let score: Swift.Float
  public let rect: CoreFoundation.CGRect
  public init(classIndex: Swift.Int, score: Swift.Float, rect: CoreFoundation.CGRect)
}
public func IOU(_ a: CoreFoundation.CGRect, _ b: CoreFoundation.CGRect) -> Swift.Float
public func nonMaxSuppression(boundingBoxes: [LivenessCloud.BoundingBox], iouThreshold: Swift.Float, maxBoxes: Swift.Int) -> [Swift.Int]
public func nonMaxSuppression(boundingBoxes: [LivenessCloud.BoundingBox], indices: [Swift.Int], iouThreshold: Swift.Float, maxBoxes: Swift.Int) -> [Swift.Int]
public func nonMaxSuppressionMultiClass(numClasses: Swift.Int, boundingBoxes: [LivenessCloud.BoundingBox], scoreThreshold: Swift.Float, iouThreshold: Swift.Float, maxPerClass: Swift.Int, maxTotal: Swift.Int) -> [Swift.Int]
@_inheritsConvenienceInitializers @available(iOS 13.0, *)
@objc public class LivenessCalculator : ObjectiveC.NSObject {
  public var isValidating: Swift.Bool
  public var additionHeader: [Swift.String : Swift.String]
  public var additionParam: [Swift.String : Any]
  @objc public func convertImageToThermalImage(frame: ARKit.ARFrame, frame_image: CoreFoundation.CGRect, current_frame: CoreFoundation.CGRect) -> UIKit.UIImage?
  @objc public func calculateLiveness(transactionId: Swift.String = "", frame: ARKit.ARFrame, isOnlyLiveness: Swift.Bool = false, onDone: ((Swift.Bool, Swift.Float, Swift.Float, Swift.Bool, Swift.String, UIKit.UIImage, LivenessCloud.LivenessResult?) -> Swift.Void)?)
  @objc override dynamic public init()
  @objc deinit
}
@objc public enum LogLevel : Swift.Int, Swift.CaseIterable {
  case verbose = 0
  case debug = 1
  case info = 2
  case warning = 3
  case error = 4
  case none = 5
  public init?(rawValue: Swift.Int)
  public typealias AllCases = [LivenessCloud.LogLevel]
  public typealias RawValue = Swift.Int
  nonisolated public static var allCases: [LivenessCloud.LogLevel] {
    get
  }
  public var rawValue: Swift.Int {
    get
  }
}
@_hasMissingDesignatedInitializers public class Log {
  public static var logLevel: LivenessCloud.LogLevel
  public static var storeLogs: Swift.Bool
  public static var logData: [Swift.String]
  public class func verbose(_ msg: @autoclosure () -> Swift.String)
  public class func debug(_ msg: @autoclosure () -> Swift.String)
  public class func info(_ msg: @autoclosure () -> Swift.String)
  public class func warning(_ msg: @autoclosure () -> Swift.String)
  public class func error(_ msg: @autoclosure () -> Swift.String)
  public class func clearStoredLogs()
  @objc deinit
}
extension Swift.Array where Element : Swift.Comparable {
  public func argmax() -> (Swift.Int, Element)
  public func argsort(by areInIncreasingOrder: (Element, Element) -> Swift.Bool) -> [Swift.Array<Element>.Index]
  public func gather(indices: [Swift.Array<Element>.Index]) -> [Element]
}
public struct TOTP {
  public init()
  public func generateRange(degree: Swift.Int, digits: LivenessCloud.OTPDigits = .six, secret: Foundation.Data, at date: Foundation.Date = .init()) throws -> [Swift.String]
  public func generate(digits: LivenessCloud.OTPDigits = .six, secret: Foundation.Data, offset: Swift.Int = 0, at date: Foundation.Date = .init()) throws -> Swift.String
}
public enum OTPDigits : Swift.Int {
  case six
  case seven
  case eight
  public init?(rawValue: Swift.Int)
  public typealias RawValue = Swift.Int
  public var rawValue: Swift.Int {
    get
  }
}
public struct ConfigData {
  public var isActiveSmile: Swift.Bool
  public var isActiveWink: Swift.Bool
}
@_inheritsConvenienceInitializers @available(iOS 13.0, *)
@objc public class LivenessUtil : ObjectiveC.NSObject {
  @objc public class func createLivenessDetector(previewView: UIKit.UIView, threshold: LivenessCloud.LivenessUtilitySensitivityThreshold = .medium, delay: Swift.Double = 0, smallFaceThreshold: Swift.Double = 0.35, debugging: Swift.Bool = false, delegate: (any LivenessCloud.LivenessUtilityDetectorDelegate)?, livenessMode: LivenessCloud.LivenessMode = .threeDimension, isWink: Swift.Bool = false, isSmile: Swift.Bool = false, isOnlyOneAction: Swift.Bool = false, frameTime: Swift.Double = 0.008, isOnlyLiveness: Swift.Bool = false, additionParam: [Swift.String : Any] = [:], additionHeader: [Swift.String : Swift.String] = [:]) -> LivenessCloud.LivenessUtilityDetector
  @objc override dynamic public init()
  @objc deinit
}
@available(iOS 13.0, *)
@objc public protocol LivenessUtilityDetectorDelegate {
  @objc optional func liveness(liveness: LivenessCloud.LivenessUtilityDetector, startLivenessAction action: LivenessCloud.LivenessAction)
  @objc optional func liveness(liveness: LivenessCloud.LivenessUtilityDetector, didFail withError: LivenessCloud.LivenessError)
  @objc optional func liveness(liveness: LivenessCloud.LivenessUtilityDetector, didFinish verificationImage: UIKit.UIImage, livenesScore: Swift.Float, faceMatchingScore: Swift.Float, result: Swift.Bool, message: Swift.String, videoURL: Foundation.URL?, response: LivenessCloud.LivenessResult?)
}
@_inheritsConvenienceInitializers @available(iOS 13.0, *)
@objc public class LivenessUtilityDetector : ObjectiveC.NSObject {
  weak public var delegate: (any LivenessCloud.LivenessUtilityDetectorDelegate)?
  public var cardId: Swift.String
  @objc public func getVerificationRequiresAndStartSession(transactionId: Swift.String = "") throws
  @objc public func stopLiveness()
  @objc override dynamic public init()
  @objc deinit
}
@objc public enum LivenessMode : Swift.Int {
  case twoDimension
  case threeDimension
  public init?(rawValue: Swift.Int)
  public typealias RawValue = Swift.Int
  public var rawValue: Swift.Int {
    get
  }
}
public func base32Encode(_ data: Foundation.Data) -> Swift.String
public func base32HexEncode(_ data: Foundation.Data) -> Swift.String
public func base32DecodeToData(_ string: Swift.String) -> Foundation.Data?
public func base32HexDecodeToData(_ string: Swift.String) -> Foundation.Data?
public func base32Encode(_ array: [Swift.UInt8]) -> Swift.String
public func base32HexEncode(_ array: [Swift.UInt8]) -> Swift.String
public func base32Decode(_ string: Swift.String) -> [Swift.UInt8]?
public func base32HexDecode(_ string: Swift.String) -> [Swift.UInt8]?
extension Swift.String {
  public var base32DecodedData: Foundation.Data? {
    get
  }
  public var base32EncodedString: Swift.String {
    get
  }
  public func base32DecodedString(_ encoding: Swift.String.Encoding = .utf8) -> Swift.String?
  public var base32HexDecodedData: Foundation.Data? {
    get
  }
  public var base32HexEncodedString: Swift.String {
    get
  }
  public func base32HexDecodedString(_ encoding: Swift.String.Encoding = .utf8) -> Swift.String?
}
extension Foundation.Data {
  public var base32EncodedString: Swift.String {
    get
  }
  public var base32EncodedData: Foundation.Data {
    get
  }
  public var base32DecodedData: Foundation.Data? {
    get
  }
  public var base32HexEncodedString: Swift.String {
    get
  }
  public var base32HexEncodedData: Foundation.Data {
    get
  }
  public var base32HexDecodedData: Foundation.Data? {
    get
  }
}
@available(iOS 13.0, tvOS 13.0, macOS 10.15, *)
extension Combine.Publisher where Self.Output : CoreML.MLFeatureProvider {
  public func prediction(model: CoreML.MLModel) -> Combine.Publishers.Map<Self, Swift.Result<any CoreML.MLFeatureProvider, any Swift.Error>>
  public func prediction(model: CoreML.MLModel) -> Combine.Publishers.CompactMap<Self, any CoreML.MLFeatureProvider>
  public func prediction(model: CoreML.MLModel) -> Combine.Publishers.TryMap<Self, (any CoreML.MLFeatureProvider)?>
}
extension ImageIO.CGImagePropertyOrientation {
  public init(_ orientation: UIKit.UIImage.Orientation)
}
extension ImageIO.CGImagePropertyOrientation {
  public init(_ orientation: UIKit.UIDeviceOrientation)
}
public func createPixelBuffer(width: Swift.Int, height: Swift.Int, pixelFormat: Darwin.OSType) -> CoreVideo.CVPixelBuffer?
public func createPixelBuffer(width: Swift.Int, height: Swift.Int) -> CoreVideo.CVPixelBuffer?
public func _createPixelBuffer(width: Swift.Int, height: Swift.Int, pixelFormat: Darwin.OSType) -> CoreVideo.CVPixelBuffer?
extension CoreVideo.CVBuffer {
  public func copyToMetalCompatible() -> CoreVideo.CVPixelBuffer?
  public func deepCopy(withAttributes attributes: [Swift.String : Any] = [:]) -> CoreVideo.CVPixelBuffer?
}
public func resizePixelBuffer(from srcPixelBuffer: CoreVideo.CVPixelBuffer, to dstPixelBuffer: CoreVideo.CVPixelBuffer, cropX: Swift.Int, cropY: Swift.Int, cropWidth: Swift.Int, cropHeight: Swift.Int, scaleWidth: Swift.Int, scaleHeight: Swift.Int)
public func resizePixelBuffer(_ srcPixelBuffer: CoreVideo.CVPixelBuffer, cropX: Swift.Int, cropY: Swift.Int, cropWidth: Swift.Int, cropHeight: Swift.Int, scaleWidth: Swift.Int, scaleHeight: Swift.Int) -> CoreVideo.CVPixelBuffer?
public func resizePixelBuffer(from srcPixelBuffer: CoreVideo.CVPixelBuffer, to dstPixelBuffer: CoreVideo.CVPixelBuffer, width: Swift.Int, height: Swift.Int)
public func resizePixelBuffer(_ pixelBuffer: CoreVideo.CVPixelBuffer, width: Swift.Int, height: Swift.Int) -> CoreVideo.CVPixelBuffer?
public func resizePixelBuffer(_ pixelBuffer: CoreVideo.CVPixelBuffer, width: Swift.Int, height: Swift.Int, output: CoreVideo.CVPixelBuffer, context: CoreImage.CIContext)
public func top(_ k: Swift.Int, _ prob: [Swift.String : Swift.Double]) -> [(Swift.String, Swift.Double)]
public func top(_ k: Swift.Int, _ observations: [Vision.VNClassificationObservation]) -> [(Swift.String, Swift.Double)]
extension UIKit.UIImage {
  public func pixelBuffer() -> CoreVideo.CVPixelBuffer?
  public func pixelBuffer(width: Swift.Int, height: Swift.Int) -> CoreVideo.CVPixelBuffer?
  public func pixelBufferGray() -> CoreVideo.CVPixelBuffer?
  public func pixelBufferGray(width: Swift.Int, height: Swift.Int) -> CoreVideo.CVPixelBuffer?
  public func pixelBuffer(width: Swift.Int, height: Swift.Int, pixelFormatType: Darwin.OSType, colorSpace: CoreGraphics.CGColorSpace, alphaInfo: CoreGraphics.CGImageAlphaInfo) -> CoreVideo.CVPixelBuffer?
}
extension UIKit.UIImage {
  convenience public init?(pixelBuffer: CoreVideo.CVPixelBuffer)
  convenience public init?(pixelBuffer: CoreVideo.CVPixelBuffer, context: CoreImage.CIContext)
}
extension CoreML.MLMultiArray {
  @nonobjc public func reshaped(to dimensions: [Swift.Int]) throws -> CoreML.MLMultiArray
  @nonobjc public func transposed(to order: [Swift.Int]) throws -> CoreML.MLMultiArray
}
extension CoreGraphics.CGImage {
  @nonobjc public func toByteArrayRGBA() -> [Swift.UInt8]
  @nonobjc public class func fromByteArrayRGBA(_ bytes: [Swift.UInt8], width: Swift.Int, height: Swift.Int) -> CoreGraphics.CGImage?
  @nonobjc public class func fromByteArrayGray(_ bytes: [Swift.UInt8], width: Swift.Int, height: Swift.Int) -> CoreGraphics.CGImage?
}
public protocol MultiArrayType : Swift.Comparable {
  static var multiArrayDataType: CoreML.MLMultiArrayDataType { get }
  static func + (lhs: Self, rhs: Self) -> Self
  static func - (lhs: Self, rhs: Self) -> Self
  static func * (lhs: Self, rhs: Self) -> Self
  static func / (lhs: Self, rhs: Self) -> Self
  init(_: Swift.Int)
  var toUInt8: Swift.UInt8 { get }
}
extension Swift.Double : LivenessCloud.MultiArrayType {
  public static var multiArrayDataType: CoreML.MLMultiArrayDataType {
    get
  }
  public var toUInt8: Swift.UInt8 {
    get
  }
}
extension Swift.Float : LivenessCloud.MultiArrayType {
  public static var multiArrayDataType: CoreML.MLMultiArrayDataType {
    get
  }
  public var toUInt8: Swift.UInt8 {
    get
  }
}
extension Swift.Int32 : LivenessCloud.MultiArrayType {
  public static var multiArrayDataType: CoreML.MLMultiArrayDataType {
    get
  }
  public var toUInt8: Swift.UInt8 {
    get
  }
}
extension CoreML.MLMultiArray {
  public func cgImage(min: Swift.Double = 0, max: Swift.Double = 255, channel: Swift.Int? = nil, axes: (Swift.Int, Swift.Int, Swift.Int)? = nil) -> CoreGraphics.CGImage?
  public func toRawBytes<T>(min: T, max: T, channel: Swift.Int? = nil, axes: (Swift.Int, Swift.Int, Swift.Int)? = nil) -> (bytes: [Swift.UInt8], width: Swift.Int, height: Swift.Int, channels: Swift.Int)? where T : LivenessCloud.MultiArrayType
}
public func createCGImage(fromFloatArray features: CoreML.MLMultiArray, min: Swift.Float = 0, max: Swift.Float = 255) -> CoreGraphics.CGImage?
extension CoreML.MLMultiArray {
  public func image(min: Swift.Double = 0, max: Swift.Double = 255, channel: Swift.Int? = nil, axes: (Swift.Int, Swift.Int, Swift.Int)? = nil) -> UIKit.UIImage?
}
public func createUIImage(fromFloatArray features: CoreML.MLMultiArray, min: Swift.Float = 0, max: Swift.Float = 255) -> UIKit.UIImage?
@objc public enum LivenessError : Swift.Int, Swift.Error {
  case noFaceDetected
  case smallFace
  case badImage
  case noVerificationInstruction
  case badResponse
  case twoFace
  case hangError
  case notSupported
  case arSessionFailed
  public init?(rawValue: Swift.Int)
  public typealias RawValue = Swift.Int
  public static var _nsErrorDomain: Swift.String {
    get
  }
  public var rawValue: Swift.Int {
    get
  }
}
@objc public enum LivenessAction : Swift.Int {
  case detectingFace
  case eyesLookIn = 1
  case smile
  case wink
  case headPoseUp
  case headPoseDown
  case headPoseLeft
  case headPoseRight
  case startVerification
  case fetchConfig
  case checkAction
  case processing
  public init?(rawValue: Swift.Int)
  public typealias RawValue = Swift.Int
  public var rawValue: Swift.Int {
    get
  }
}
@_hasMissingDesignatedInitializers @objc public class ImageAction : ObjectiveC.NSObject {
  public var action: LivenessCloud.LivenessAction?
  public var image: Swift.String?
  @objc deinit
}
@objc public enum LivenessUtilitySensitivityThreshold : Swift.Int {
  case low = 1
  case medium
  case high
  public init?(rawValue: Swift.Int)
  public typealias RawValue = Swift.Int
  public var rawValue: Swift.Int {
    get
  }
}
@available(iOS 15.0, *)
@objc public class DepthLivenessDetector : LivenessCloud.LivenessUtilityDetector {
  @objc public init(previewView: UIKit.UIView, threshold: LivenessCloud.LivenessUtilitySensitivityThreshold = .high, delay: Swift.Double = 0, smallFaceThreshold: Swift.Double = 0.35, debugging: Swift.Bool = true, isWink: Swift.Bool = false, isSmile: Swift.Bool = false, isOnlyOneAction: Swift.Bool = false, transactionId: Swift.String = "", frameTime: Swift.Double = 0.008, isOnlyLiveness: Swift.Bool = false)
  @objc public func startLivenessDetection()
  @objc override public func getVerificationRequiresAndStartSession(transactionId: Swift.String = "") throws
  @objc override public func stopLiveness()
  @objc deinit
}
@available(iOS 15.0, *)
extension LivenessCloud.DepthLivenessDetector : ARKit.ARSessionDelegate {
  @objc dynamic public func session(_ session: ARKit.ARSession, didFailWithError error: any Swift.Error)
  @objc dynamic public func session(_ session: ARKit.ARSession, didUpdate frame: ARKit.ARFrame)
  @objc dynamic public func session(_ session: ARKit.ARSession, didUpdate anchors: [ARKit.ARAnchor])
}
@available(iOS 15.0, *)
extension LivenessCloud.DepthLivenessDetector : ARKit.ARSCNViewDelegate {
  @objc dynamic public func renderer(_ renderer: any SceneKit.SCNSceneRenderer, didRemove node: SceneKit.SCNNode, for anchor: ARKit.ARAnchor)
  @objc dynamic public func renderer(_ renderer: any SceneKit.SCNSceneRenderer, didAdd node: SceneKit.SCNNode, for anchor: ARKit.ARAnchor)
  @objc dynamic public func renderer(_ renderer: any SceneKit.SCNSceneRenderer, didUpdate node: SceneKit.SCNNode, for anchor: ARKit.ARAnchor)
}
@objc @objcMembers public class LivenessResponse : ObjectiveC.NSObject, ObjectMapper.Mappable {
  @objc public var status: Swift.Int
  @objc public var data: Swift.String
  @objc public var signature: Swift.String
  required public init?(map: ObjectMapper.Map)
  public func mapping(map: ObjectMapper.Map)
  @objc deinit
}
@objc @objcMembers public class LivenessResult : ObjectiveC.NSObject, ObjectMapper.Mappable {
  @objc public var status: Swift.Int
  @objc public var data: [Swift.String : Any]
  @objc public var signature: Swift.String
  @objc public var livenesScore: Swift.Float
  @objc public var faceMatchingScore: Swift.Float
  @objc public var succes: Swift.Bool
  @objc public var sim: Swift.Float
  @objc public var livenessType: Swift.String
  @objc public var mess: Swift.String
  @objc public var code: Swift.String
  @objc public var request_id: Swift.String
  required public init?(map: ObjectMapper.Map)
  public func mapping(map: ObjectMapper.Map)
  @objc deinit
}
extension UIKit.UIImage {
  @nonobjc public func resized(to newSize: CoreFoundation.CGSize, scale: CoreFoundation.CGFloat = 1) -> UIKit.UIImage
  @nonobjc public func rotated(by degrees: CoreFoundation.CGFloat, keepSize: Swift.Bool = true) -> UIKit.UIImage
}
extension LivenessCloud.LogLevel : Swift.Equatable {}
extension LivenessCloud.LogLevel : Swift.Hashable {}
extension LivenessCloud.LogLevel : Swift.RawRepresentable {}
extension LivenessCloud.OTPDigits : Swift.Equatable {}
extension LivenessCloud.OTPDigits : Swift.Hashable {}
extension LivenessCloud.OTPDigits : Swift.RawRepresentable {}
extension LivenessCloud.LivenessMode : Swift.Equatable {}
extension LivenessCloud.LivenessMode : Swift.Hashable {}
extension LivenessCloud.LivenessMode : Swift.RawRepresentable {}
extension LivenessCloud.LivenessError : Swift.Equatable {}
extension LivenessCloud.LivenessError : Swift.Hashable {}
extension LivenessCloud.LivenessError : Swift.RawRepresentable {}
extension LivenessCloud.LivenessAction : Swift.Equatable {}
extension LivenessCloud.LivenessAction : Swift.Hashable {}
extension LivenessCloud.LivenessAction : Swift.RawRepresentable {}
extension LivenessCloud.LivenessUtilitySensitivityThreshold : Swift.Equatable {}
extension LivenessCloud.LivenessUtilitySensitivityThreshold : Swift.Hashable {}
extension LivenessCloud.LivenessUtilitySensitivityThreshold : Swift.RawRepresentable {}
